<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>VyPR - Performance Analysis for Python Programs</title>

    <!-- Bootstrap -->
    <link href="../static/css/bootstrap.min.css" rel="stylesheet" />

    <link href="../static/css/custom.css" rel="stylesheet" />

    <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script type="text/javascript" src="../static/js/bootstrap.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
  	<nav class="navbar navbar">
  	  <div class="container-fluid">
  	    <!-- Brand and toggle get grouped for better mobile display -->
  	    <div class="navbar-header">
          <a class="navbar-brand" href="../index.html"><img src="../static/images/vypr_logo.jpeg" height="50px" margin-top="-10px" /></a>
        </div>

  	    <!-- nav links -->
  	    <div class="collapse navbar-collapse" id="navbar">
  	      <ul class="nav navbar-nav">
  	        <!--<li><a href="tutorial.html">Tutorial</a></li>-->
            <li><a href="../use-vypr.html">Get Started with VyPR</a></li>
            <li><a href="../publications.html">Research</a></li>
            <li><a href="../team.html">Team</a></li>
            <li><a href="../licence.html">Licence</a></li>
  	      </ul>
  	    </div><!-- /.navbar-collapse -->
  	  </div><!-- /.container-fluid -->
  	</nav>

	<div class="container">
    <nav>
      <ul class="pager">
        <li><a href="../use-vypr.html">Getting Started with VyPR</a></li>
        <li><a href="../writing-queries/index.html">Writing Queries</a></li>
        <li><a href="../analysis-environment/index.html">Web-based Analysis Environment</a></li>
        <li><a href="index.html">Python Analysis Library</a></li>
      </ul>
    </nav>

    <div class="container">
      <h1>Introduction to VyPR's Python Analysis Library</h1><br />
      <div class="col-md-3">
        <ul class="nav nav-pills nav-stacked">
          <li role="presentation"><a href="index.html">Home</a></li>
          <li role="presentation"><a href="offline-analysis-part-1.html">Example 1</a></li>
          <li role="presentation"><a href="offline-analysis-part-2.html">Example 2</a></li>
          <li role="presentation" class="active"><a href="offline-analysis-part-3.html">Example 3</a></li>
        </ul>
      </div>
      <div class="col-md-8">
      <h2> Hash checking effectiveness analysis </h2>
      <p> In this script we will show an example of using the VyPR Analysis Library to visualise the
        effectiveness of hash checking in optimising the Conditions upload process. The upload service
        deals with data gathered at the CMS Experiment at the LHC at CERN, providing mechanisms for
        segmenting large sets of conditions while releasing them to the production database. The service
        is split into client and server-side that communicate via HTTPS requests. Due to a large amount of
        data, optimising the data transfer to the server is of key importance. </p>
      <p> One of the methods implemented with the aim of improving the upload service is hash checking -
        sending an HTTPS request to the server-side containing the list of hashes computed locally and
        getting the list of Payload hashes that were not found in the destination Conditions database as
        a response, therefore reducing the amount of data sent to the server by omitting the data that is
        already existing in the database. In some cases, this optimisation resulted in reducing the time
        taken by the upload by an order of magnitude since all the hashes were found.</p>
      <p> However, it is possible that the most of the hashes are not found in the database, in which
        case the hash checking process could take a lot of time while not reducing the number of uploads
        significantly. VyPR monitored the upload process at runtime, gathering data we now want to analyse.
        The monitored service was checked for the requirement that the number of hashes not found should
        exceed 70% of the original list of hashes. The intuition here is that the optimisation should have
        a sufficient effect on the upload process that its removal would cause significantly different
        behaviour. </p>
      <h2> Importing modules </h2>
      <p> Begin with importing the necessary modules and setting up the verdict server.</p>
      <pre>
import sys
sys.path.append("..")
import ast
import pprint
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import matplotlib.cbook as cbook
from dateutil.parser import isoparse
import traceback
import json
import argparse

import VyPRAnalysis as va
va.prepare("verdicts-hash-checking-analysis.db")
va.set_monitored_service_path("uploader-experiments/uploader/")
      </pre>

      <h2> Measured values of the hashes array lengths</h2>

      <p> Iterate through the calls of the hash checking function to gather the observed number of the
        checked hashes during each call, as well as the number of those that were not found. </p>

      <pre>
hash_checking_function = va.list_functions()[0]
all_calls = hash_checking_function.get_calls()
n_of_calls = len(all_calls)

hashes_length_to_not_found_list = {}

hash_lengths = []

for (n, call) in enumerate(all_calls):
  if n % 100 == 0:
    print("Processed %i/%i calls." % (n, n_of_calls))
  # there will be a single verdict
  verdict = call.get_verdicts()[0]
  # in case we only care about failing verdicts replace the conditional with:
  #if verdict.verdict == 0:
  if True:
    observations = verdict.get_observations()
    lhs_obs = filter(lambda obs : obs.sub_index == 0, observations)[0]
    rhs_obs = filter(lambda obs : obs.sub_index == 1, observations)[0]
    total_hashes = ast.literal_eval(lhs_obs.observed_value)["hashes"]

    if total_hashes in hash_lengths:
      length_index = hash_lengths.index(total_hashes)
    else:
      hash_lengths.append(total_hashes)
      length_index = len(hash_lengths)-1

    not_found = ast.literal_eval(rhs_obs.observed_value)["not_found"]
    if length_index not in hashes_length_to_not_found_list:
      hashes_length_to_not_found_list[length_index] = [not_found]
    else:
      hashes_length_to_not_found_list[length_index].append(not_found)
      </pre>

      <p> Convert the gathered lengths of the not found and all checked hashes into percentage values. </p>

      <pre>
hashes_length_to_percentages = {}
for hash_length_index in hashes_length_to_not_found_list:
  n_of_hashes_given = hash_lengths[hash_length_index]
  percentages = []

  for not_found in hashes_length_to_not_found_list[hash_length_index]:
    percentages.append(100*(float(not_found)/float(n_of_hashes_given)))

  hashes_length_to_percentages[hash_length_index] = percentages
      </pre>

      <p> Manually construct the bins for hash lengths and group the percentages into corresponding bins. </p>

      <pre>
bins = [[0, 10], [10, 20], [20, 30], [30, 40], [40, 50], [50, 60], [60, 80], [80, 100], [100, 200], [200, 300], [300, 2000]]
groups = [[] for bin in bins]

bin_as_label = lambda bin : "[%i, %i)" % tuple(bin)
bin_strings = map(bin_as_label, bins)

# put hash lengths into bins
for (length_index, hash_length) in enumerate(hash_lengths):
  for (n, bin) in enumerate(bins):
    if bin[0] <= hash_length < bin[1]:
      groups[n] += hashes_length_to_percentages[length_index]
      </pre>

      <h2> Plotting the percentages of hashes not found </h2>

      <p> Finally, create the plot showing the boxplots showing the distribution of the percentage of the
        hashes not found, grouped by the total number of hashes checked. We see that Conditions uploads
        which propose a high number of Payloads often upload Conditions that do not already exist. From
        this we take two key results: </p>
      <ul>
        <li> We must consider making hash checking an optional part of the Conditions upload process if it
        takes a long time in cases where it has little benefit </li>
        <li> Instances where hash checking takes a long time are often those where the Payloads do not exist,
        so the problem in these instances cannot be that the checking query is fetching too much data. </li>
      </ul>

      <pre>
# derive boxplot statistics
stats = cbook.boxplot_stats(groups, labels=bin_strings)

# draw plot
fig, ax = plt.subplots()

fig.set_figheight(4)
fig.set_figwidth(10)

plt.xticks(rotation=45)

plt.ylim([0, 100])

plt.xlabel("Number of hashes checked")
plt.ylabel("Percentage of hashes not found")

ax.bxp(stats, showfliers=False)

plt.tight_layout()
plt.show()
      </pre>

    <img src="../static/images/hash_checking_plot_example.png" width="750px">
      </div>
    </div>

  </div>

</body>
</html>
